{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f443c853",
   "metadata": {},
   "source": [
    "# Analyzing Textual Data with NLTK\n",
    "\n",
    "In this project, I dive deep into the world of Natural Language Processing (NLP) using the Natural Language Toolkit (NLTK). My primary objective is to analyze a text document and extract meaningful insights by tokenizing text, performing part-of-speech tagging, and syntactic parsing.\n",
    "\n",
    "**Data Source**: The text corpus is sourced from [Prof. Dr. Marc Hellmuth](https://math-inf.uni-greifswald.de/storages/uni-greifswald/fakultaet/mnf/mathinf/hellmuth/Teaching/AlgorDatastrWS1819/Goethe--Faust.txt) of the University of Greifswald.\n",
    "\n",
    "**Key Project Objectives:**\n",
    "\n",
    "1. **Import Libraries**: I start by importing essential libraries for text processing, including NLTK and custom functions for tokenization and chunk counting.\n",
    "\n",
    "2. **Load Data**: The text document from \"Faust\" by Goethe is loaded, converted to lowercase, and prepared for analysis.\n",
    "\n",
    "3. **Tokenize Text**: I tokenize the text into sentences and further split them into words, enabling granular analysis.\n",
    "\n",
    "4. **Part-of-Speech Tagging**: Each word in the text is tagged with its respective part of speech, providing linguistic context and structure to the text.\n",
    "\n",
    "5. **Syntactic Parsing**: I perform syntactic parsing by chunking sentences into noun phrases (NPs) and verb phrases (VPs) using predefined grammars.\n",
    "\n",
    "6. **Visualize Chunks**: To gain a visual understanding, I search for specific words, like \"klug,\" and visualize sentences containing these words as trees, revealing their grammatical structure.\n",
    "\n",
    "7. **Analyze Chunks**: I analyze the most common NP-chunks and VP-chunks in the text. This analysis provides insights into the prominent characters, entities, and themes within the text.\n",
    "\n",
    "**Summary:**  \n",
    "My journey through \"Faust\" by Goethe unveils fascinating aspects of the text. I discover the significance of characters like \"Faust\" and \"Margarete\" based on their frequent appearance as NP-chunks. Additionally, my analysis of VP-chunks sheds light on Goethe's unique writing style and the absence of conventional grammatical structures, contributing to a deeper understanding of the text's literary nuances. This code project exemplifies the power of NLP techniques in unraveling the intricacies of textual data.\n",
    "\n",
    "*Note: The code provided serves as an illustrative example and can be applied to a wide range of textual analyses.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fb419",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d62ce9",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16fbe82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, RegexpParser, Tree\n",
    "import pprint\n",
    "import import_ipynb\n",
    "from functions.tokenize_words import word_sentence_tokenize\n",
    "from functions.chunk_counters import np_chunk_counter, vp_chunk_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6b74b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import text\n",
    "text = open(\"text/faust.txt\",encoding='utf-8').read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7271f5c8",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Sentence:\n",
      "['was', 'hilft', 'es', 'viel', 'von', 'stimmung', 'reden', '?']\n"
     ]
    }
   ],
   "source": [
    "# Split the text into individual sentences and word tokenize them\n",
    "word_tokenized_text = word_sentence_tokenize(text)\n",
    "\n",
    "# Specify the sentence index you want to print\n",
    "sentence_index = 100\n",
    "\n",
    "# Print a single word-tokenized sentence\n",
    "if sentence_index < len(word_tokenized_text):\n",
    "    selected_sentence = word_tokenized_text[sentence_index]\n",
    "    print(\"Selected Sentence:\")\n",
    "    print(selected_sentence)\n",
    "else:\n",
    "    print(f\"Sentence index {sentence_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-of-speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Part-of-Speech Tagged Sentence:\n",
      "[('was', 'VBD'), ('hilft', 'JJ'), ('es', 'JJ'), ('viel', 'NN'), ('von', 'NN'), ('stimmung', 'NN'), ('reden', 'NN'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Create a list to hold part-of-speech tagged sentences\n",
    "pos_tagged_text = [pos_tag(sentence) for sentence in word_tokenized_text]\n",
    "\n",
    "# Check if the specified sentence index is within a valid range\n",
    "if 0 <= sentence_index < len(pos_tagged_text):\n",
    "    # Select and print a part-of-speech tagged sentence\n",
    "    selected_sentence = pos_tagged_text[sentence_index]\n",
    "    print(\"Selected Part-of-Speech Tagged Sentence:\")\n",
    "    print(selected_sentence)\n",
    "else:\n",
    "    # Handle the case where the sentence index is out of range\n",
    "    print(f\"Sentence index {sentence_index} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bad3d9",
   "metadata": {},
   "source": [
    "### Chunk Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define noun phrase and verb phrase chunk grammars\n",
    "np_chunk_grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "vp_chunk_grammar = \"VP: {<DT>?<JJ>*<NN><VB.*><RB.?>?}\"\n",
    "\n",
    "# Create RegexpParser objects for both noun phrases and verb phrases\n",
    "np_chunk_parser = RegexpParser(np_chunk_grammar)\n",
    "vp_chunk_parser = RegexpParser(vp_chunk_grammar)\n",
    "\n",
    "# Create lists to hold noun phrase chunked sentences and verb phrase chunked sentences\n",
    "np_chunked_text = list()\n",
    "vp_chunked_text = list()\n",
    "\n",
    "# Iterate through each part-of-speech tagged sentence\n",
    "for pos_tagged_sentence in pos_tagged_text:\n",
    "    # Perform noun phrase chunking and append to the noun phrase chunked list\n",
    "    np_chunked_text.append(np_chunk_parser.parse(pos_tagged_sentence))\n",
    "    \n",
    "    # Perform verb phrase chunking and append to the verb phrase chunked list\n",
    "    vp_chunked_text.append(vp_chunk_parser.parse(pos_tagged_sentence))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a6698",
   "metadata": {},
   "source": [
    "### Visualize Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68f300",
   "metadata": {},
   "source": [
    "To visually inspect the part-of-speach tagged chunks we can use the pretty print function. In the followin, I will search for the word \"klug\", and visualize all sentences that contain the word as a tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "24f22364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty Print of Matching Sentence:\n",
      "                                                                                                                                                                        S                                                                                                                                                                                                                \n",
      "   _____________________________________________________________________________________________________________________________________________________________________|___________________________________________________________________________________________________________________________________________________________________________________________________________      \n",
      "  |      |       |       |     |     |      |   |      |      |   |   |   |    |      |          |       |          NP           NP         NP        NP        NP      NP           NP                 NP           NP       NP       NP       NP            NP           NP      NP       NP        NP            NP           NP      NP            NP           NP     NP       NP   \n",
      "  |      |       |       |     |     |      |   |      |      |   |   |   |    |      |          |       |     _____|____        |          |         |         |       |       _____|_____         ____|____        |        |        |        |        _____|_____       |       |        |         |         ____|____        |       |        _____|_____       |      |        |     \n",
      "so/RB klug/JJ als/NNS wie/VBP ;/: heiße/CC ,/, ,/, schon/VBD ,/, ,/, ,/, --/: ,/, nichts/NNS wissen/VBP !/. und/JJ     bin/NN zuvor/NN magister/NN heiße/NN doctor/NN gar/NN und/JJ     ziehe/NN an/DT     die/NN zehen/NN jahr/NN herauf/NN herab/NN und/JJ     quer/NN und/NN krumm/NN meine/NN schüler/NN an/DT     der/NN nase/NN herum/NN und/JJ     sehe/NN daß/NN wir/NN können/NN\n",
      "\n",
      "Pretty Print of Matching Sentence:\n",
      "                            S                                           \n",
      "  __________________________|_______________________________________     \n",
      " |   |     NP       NP            NP               NP      NP       NP  \n",
      " |   |     |        |        _____|_______         |       |        |    \n",
      ",/, !/. mein/NN freund/NN nun/JJ     sprichst/NN du/NN wieder/NN klug/NN\n",
      "\n",
      "Pretty Print of Matching Sentence:\n",
      "       S           \n",
      "  _____|_______     \n",
      " |     NP      NP  \n",
      " |     |       |    \n",
      "!/. sehr/NN klug/NN\n",
      "\n",
      "Pretty Print of Matching Sentence:\n",
      "                                                                                         S                                                                                                                                   \n",
      "  _______________________________________________________________________________________|_____________________________________________________________________________________________________________________________       \n",
      " |   |    |        |        |    |   |          NP             NP           NP           NP       NP       NP                 NP          NP          NP               NP                 NP        NP        NP       NP    \n",
      " |   |    |        |        |    |   |     _____|_____         |       _____|____        |        |        |           _______|____       |           |           _____|_________         |         |         |        |      \n",
      ",/, ;/: zum/CC brocken/VB in/IN ,/, ./. ich/JJ     denke/NN doch/NN das/JJ     war/NN recht/NN klug/NN gemacht/NN wandeln/JJ     wir/NN der/NN walpurgisnacht/ um/JJ uns/JJ beliebig/NN nun/NN hieselbst/NN zu/NN isoliren/NN\n",
      "                                                                                                                                                      NN                                                                     \n",
      "\n",
      "Pretty Print of Matching Sentence:\n",
      "                                                         S                                                                                 \n",
      "  _______________________________________________________|__________________________________________________________________________        \n",
      " |     |     |   |    NP    NP           NP              NP        NP       NP           NP           NP            NP              NP     \n",
      " |     |     |   |    |     |       _____|_____          |         |        |       _____|_____       |        _____|_____          |       \n",
      "'/'' und/IN ,/, ./. da/NN seh/NN ich/JJ     junge/NN hexchen/NN nackt/NN bloß/NN und/JJ     alte/NN die/NN sich/JJ     klug/NN verhüllen/NN\n",
      "\n",
      "Pretty Print of Matching Sentence:\n",
      "                                 S                                               \n",
      "   ______________________________|__________________________________________      \n",
      "  |     |      |    |    NP      NP             NP                 NP       NP   \n",
      "  |     |      |    |    |       |        ______|________          |        |     \n",
      "so/RB 's/POS in/IN ./. wir/NN sind/NN klug/JJ und/JJ dennoch/NN spukt/NN tegel/NN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a function to search for a word in the parsed text\n",
    "def search_word_in_parsed_text(parsed_text, target_word):\n",
    "    # Initialize an empty list to store matching sentences\n",
    "    matching_sentences = []\n",
    "\n",
    "    # Iterate through each parsed sentence\n",
    "    for sentence in parsed_text:\n",
    "        # Extract the words from the sentence\n",
    "        words = [word[0] for word in sentence.leaves()]\n",
    "        \n",
    "        # Check if the target word is in the list of words\n",
    "        if target_word in words:\n",
    "            # If found, add the sentence to the list of matching sentences\n",
    "            matching_sentences.append(sentence)\n",
    "    \n",
    "    return matching_sentences\n",
    "\n",
    "# Search for the word \"klug\" in the parsed text\n",
    "target_word = \"klug\"\n",
    "matching_sentences = search_word_in_parsed_text(np_chunked_text, target_word)\n",
    "\n",
    "# Pretty print each matching sentence as an nltk.Tree object (if any)\n",
    "if matching_sentences:\n",
    "    for sentence in matching_sentences:\n",
    "        tree = Tree.fromstring(str(sentence))\n",
    "        print(\"Pretty Print of Matching Sentence:\")\n",
    "        tree.pretty_print()\n",
    "else:\n",
    "    print(f\"The word '{target_word}' was not found in the parsed text.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df8deb6",
   "metadata": {},
   "source": [
    "Moving on to the analysis of the text, we can draw on the frequency of occurences of specific chunks to infer about a texts content and themes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((('faust', 'NN'),), 444), ((('der', 'NN'),), 422), ((('die', 'NN'),), 354), ((('zu', 'NN'),), 253), ((('du', 'NN'),), 202), ((('goethe', 'NN'),), 201), ((('ein', 'NN'),), 179), ((('sie', 'NN'),), 173), ((('mir', 'NN'),), 168), ((('mit', 'NN'),), 162), ((('ihr', 'NN'),), 139), ((('dem', 'NN'),), 135), ((('es', 'NN'),), 126), ((('auf', 'NN'),), 118), ((('und', 'NN'),), 114), ((('er', 'NN'),), 113), ((('wie', 'NN'),), 109), ((('nicht', 'NN'),), 109), ((('doch', 'NN'),), 99), ((('ist', 'NN'),), 99), ((('mich', 'NN'),), 93), ((('da', 'NN'),), 92), ((('man', 'NN'),), 82), ((('daß', 'NN'),), 77), ((('margarete', 'NN'),), 73), ((('den', 'NN'),), 70), ((('im', 'NN'),), 69), ((('wir', 'NN'),), 69), ((('dir', 'NN'),), 69), ((('von', 'NN'),), 66)]\n"
     ]
    }
   ],
   "source": [
    "# Store and print the most common NP-chunks\n",
    "most_common_np_chunks = np_chunk_counter(np_chunked_text)\n",
    "print(most_common_np_chunks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9488ba",
   "metadata": {},
   "source": [
    "**Summary:**  \n",
    "Looking at `most_common_np_chunks`,   which based on the `np_chunk_counter()` functionreturns the `30` most common NP-chunks from a list of chunked sentences, we can identify characters of importance in the text. Specifically we find that \"Faust,\" \"Goethe,\" and \"Margarete\" are likely names of characters or entities in the text that are important  in understanding the characters and the storyline based on their frequency of occurence. Given that the text is authored by Goethe, a features a protagonist called \"Faust\" who falls in love with \"Margarete\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((('bei', 'NN'), (\"'m\", 'VBP')), 15), ((('und', 'NN'), ('was', 'VBD')), 13), ((('die', 'NN'), ('welt', 'VBD')), 7), ((('ich', 'NN'), ('mich', 'VBD')), 5), ((('nicht', 'NN'), ('was', 'VBD')), 5), ((('auch', 'NN'), ('was', 'VBD')), 4), ((('ein', 'NN'), ('ganzes', 'VBZ')), 3), ((('der', 'NN'), ('welt', 'VBD')), 3), ((('ich', 'NN'), ('was', 'VBD')), 3), ((('sich', 'NN'), ('die', 'VBP')), 3), ((('für', 'NN'), ('was', 'VBD')), 3), ((('herrlich', 'JJ'), ('wie', 'NN'), ('am', 'VBP')), 2), ((('sessel', 'NN'), ('am', 'VBP')), 2), ((('zeichen', 'NN'), ('des', 'VBZ')), 2), ((('man', 'NN'), ('sie', 'VBZ')), 2), ((('bess', 'NN'), (\"'re\", 'VBP')), 2), ((('mich', 'NN'), ('was', 'VBD')), 2), ((('nicht', 'NN'), ('die', 'VBP')), 2), ((('mit', 'NN'), ('tausend', 'VBP')), 2), ((('die', 'NN'), ('sich', 'VBD')), 2), ((('verflucht', 'NN'), ('was', 'VBD')), 2), ((('dir', 'NN'), ('was', 'VBD')), 2), ((('gern', 'NN'), ('was', 'VBD')), 2), ((('mir', 'NN'), ('ein', 'VBP')), 2), ((('wir', 'NN'), ('knicken', 'VBN')), 2), ((('gleich', 'NN'), ('wenn', 'VBD')), 2), ((('ein', 'NN'), ('gutes', 'VBZ')), 2), ((('mein', 'NN'), ('busen', 'VBZ')), 2), ((('vor', 'NN'), (\"'m\", 'VBP')), 2), ((('nur', 'NN'), ('die', 'VBP')), 2)]\n"
     ]
    }
   ],
   "source": [
    "# store and print the most common VP-chunks here\n",
    "most_common_vp_chunks = vp_chunk_counter(vp_chunked_text)\n",
    "print(most_common_vp_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6c18c0",
   "metadata": {},
   "source": [
    "**Summary:**  \n",
    "Looking at `most_common_vp_chunks`, we can see that verb phrases of the form we defined in our chunk grammar do not appear as often in Faust as noun phrases. This indicates Goethe's unique style of writing, which does not necessarily follow traditional grammatical style (i.e. poetry). The absence of chunks thus gives us insight as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
